{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# fix for MacOS \n",
    "#\n",
    "# from https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "#\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([\n",
    "                        transforms.RandomRotation(30),\n",
    "                        transforms.RandomResizedCrop(224),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor()\n",
    "                        ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=2, bias=True)\n",
       "  (output): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
    "\n",
    "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cpu; Time per batch: 6.299 seconds\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu'] :   #['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Move input and label tensors to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
    "```python\n",
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Use a pretrained model to classify the cat and dog images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device={device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "# freese paaremters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace classifier\n",
    "classifier = nn.Sequential(\n",
    "                    nn.Linear(2048,512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=0.2),\n",
    "                    nn.Linear(512,2),\n",
    "                    nn.LogSoftmax(dim=1)\n",
    "                )\n",
    "model.fc = classifier\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 Batch 1/390 Train loss 0.692 Time per batch: 18.220 seconds\n",
      "Epoch 1/1 Batch 2/390 Train loss 1.016 Time per batch: 18.563 seconds\n",
      "Epoch 1/1 Batch 3/390 Train loss 0.834 Time per batch: 18.272 seconds\n",
      "Epoch 1/1 Batch 4/390 Train loss 0.957 Time per batch: 17.831 seconds\n",
      "Epoch 1/1 Batch 5/390 Train loss 0.988 Time per batch: 17.385 seconds\n",
      "Epoch 1/1 Batch 6/390 Train loss 0.896 Time per batch: 17.064 seconds\n",
      "Epoch 1/1 Batch 7/390 Train loss 0.839 Time per batch: 16.882 seconds\n",
      "Epoch 1/1 Batch 8/390 Train loss 0.820 Time per batch: 16.720 seconds\n",
      "Epoch 1/1 Batch 9/390 Train loss 0.791 Time per batch: 16.557 seconds\n",
      "Epoch 1/1 Batch 10/390 Train loss 0.746 Time per batch: 16.500 seconds\n",
      "Epoch 1/1 Batch 11/390 Train loss 0.711 Time per batch: 16.529 seconds\n",
      "Epoch 1/1 Batch 12/390 Train loss 0.681 Time per batch: 16.550 seconds\n",
      "Epoch 1/1 Batch 13/390 Train loss 0.658 Time per batch: 16.571 seconds\n",
      "Epoch 1/1 Batch 14/390 Train loss 0.635 Time per batch: 16.588 seconds\n",
      "Epoch 1/1 Batch 15/390 Train loss 0.612 Time per batch: 16.595 seconds\n",
      "Epoch 1/1 Batch 16/390 Train loss 0.587 Time per batch: 16.628 seconds\n",
      "Epoch 1/1 Batch 17/390 Train loss 0.577 Time per batch: 16.663 seconds\n",
      "Epoch 1/1 Batch 18/390 Train loss 0.564 Time per batch: 16.615 seconds\n",
      "Epoch 1/1 Batch 19/390 Train loss 0.552 Time per batch: 16.538 seconds\n",
      "Epoch 1/1 Batch 20/390 Train loss 0.539 Time per batch: 16.471 seconds\n",
      "Epoch 1/1 Batch 21/390 Train loss 0.524 Time per batch: 16.493 seconds\n",
      "Epoch 1/1 Batch 22/390 Train loss 0.513 Time per batch: 16.531 seconds\n",
      "Epoch 1/1 Batch 23/390 Train loss 0.502 Time per batch: 16.566 seconds\n",
      "Epoch 1/1 Batch 24/390 Train loss 0.496 Time per batch: 16.558 seconds\n",
      "Epoch 1/1 Batch 25/390 Train loss 0.486 Time per batch: 16.576 seconds\n",
      "Epoch 1/1 Batch 26/390 Train loss 0.476 Time per batch: 16.566 seconds\n",
      "Epoch 1/1 Batch 27/390 Train loss 0.465 Time per batch: 16.568 seconds\n",
      "Epoch 1/1 Batch 28/390 Train loss 0.454 Time per batch: 16.568 seconds\n",
      "Epoch 1/1 Batch 29/390 Train loss 0.443 Time per batch: 16.603 seconds\n",
      "Epoch 1/1 Batch 30/390 Train loss 0.433 Time per batch: 16.612 seconds\n",
      "Epoch 1/1 Batch 31/390 Train loss 0.426 Time per batch: 16.562 seconds\n",
      "Epoch 1/1 Batch 32/390 Train loss 0.420 Time per batch: 16.528 seconds\n",
      "Epoch 1/1 Batch 33/390 Train loss 0.413 Time per batch: 16.510 seconds\n",
      "Epoch 1/1 Batch 34/390 Train loss 0.405 Time per batch: 16.474 seconds\n",
      "Epoch 1/1 Batch 35/390 Train loss 0.400 Time per batch: 16.446 seconds\n",
      "Epoch 1/1 Batch 36/390 Train loss 0.394 Time per batch: 16.416 seconds\n",
      "Epoch 1/1 Batch 37/390 Train loss 0.388 Time per batch: 16.383 seconds\n",
      "Epoch 1/1 Batch 38/390 Train loss 0.383 Time per batch: 16.354 seconds\n",
      "Epoch 1/1 Batch 39/390 Train loss 0.378 Time per batch: 16.365 seconds\n",
      "Epoch 1/1 Batch 40/390 Train loss 0.372 Time per batch: 16.350 seconds\n",
      "Epoch 1/1 Batch 41/390 Train loss 0.366 Time per batch: 16.361 seconds\n",
      "Epoch 1/1 Batch 42/390 Train loss 0.360 Time per batch: 16.369 seconds\n",
      "Epoch 1/1 Batch 43/390 Train loss 0.356 Time per batch: 16.342 seconds\n",
      "Epoch 1/1 Batch 44/390 Train loss 0.352 Time per batch: 16.322 seconds\n",
      "Epoch 1/1 Batch 45/390 Train loss 0.350 Time per batch: 16.357 seconds\n",
      "Epoch 1/1 Batch 46/390 Train loss 0.346 Time per batch: 16.409 seconds\n",
      "Epoch 1/1 Batch 47/390 Train loss 0.343 Time per batch: 16.436 seconds\n",
      "Epoch 1/1 Batch 48/390 Train loss 0.341 Time per batch: 16.453 seconds\n",
      "Epoch 1/1 Batch 49/390 Train loss 0.336 Time per batch: 16.472 seconds\n",
      "Epoch 1/1 Batch 50/390 Train loss 0.333 Time per batch: 16.464 seconds\n",
      "Epoch 1/1 Batch 51/390 Train loss 0.330 Time per batch: 16.451 seconds\n",
      "Epoch 1/1 Batch 52/390 Train loss 0.326 Time per batch: 16.440 seconds\n",
      "Epoch 1/1 Batch 53/390 Train loss 0.322 Time per batch: 16.434 seconds\n",
      "Epoch 1/1 Batch 54/390 Train loss 0.319 Time per batch: 16.451 seconds\n",
      "Epoch 1/1 Batch 55/390 Train loss 0.317 Time per batch: 16.485 seconds\n",
      "Epoch 1/1 Batch 56/390 Train loss 0.314 Time per batch: 16.560 seconds\n",
      "Epoch 1/1 Batch 57/390 Train loss 0.311 Time per batch: 16.611 seconds\n",
      "Epoch 1/1 Batch 58/390 Train loss 0.309 Time per batch: 16.644 seconds\n",
      "Epoch 1/1 Batch 59/390 Train loss 0.308 Time per batch: 16.663 seconds\n",
      "Epoch 1/1 Batch 60/390 Train loss 0.307 Time per batch: 16.661 seconds\n",
      "Epoch 1/1 Batch 61/390 Train loss 0.306 Time per batch: 16.663 seconds\n",
      "Epoch 1/1 Batch 62/390 Train loss 0.305 Time per batch: 16.665 seconds\n",
      "Epoch 1/1 Batch 63/390 Train loss 0.303 Time per batch: 16.667 seconds\n",
      "Epoch 1/1 Batch 64/390 Train loss 0.302 Time per batch: 16.673 seconds\n",
      "Epoch 1/1 Batch 65/390 Train loss 0.299 Time per batch: 16.662 seconds\n",
      "Epoch 1/1 Batch 66/390 Train loss 0.297 Time per batch: 16.677 seconds\n",
      "Epoch 1/1 Batch 67/390 Train loss 0.294 Time per batch: 16.698 seconds\n",
      "Epoch 1/1 Batch 68/390 Train loss 0.292 Time per batch: 16.704 seconds\n"
     ]
    }
   ],
   "source": [
    "## TODO: Use a pretrained model to classify the cat and dog images\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    start = time.time()\n",
    "    batch = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        # Move input and label tensors to the GPU or CPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  #prepare gradients for a new step\n",
    "        \n",
    "        log_ps = model(images)   # make a forward step.\n",
    "        loss = criterion(log_ps, labels)  # calcualte loss function\n",
    "        loss.backward()       # make a backstep on loss value\n",
    "        optimizer.step()      # recalculate network weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        batch += 1\n",
    "        \n",
    "        print(\"Epoch {}/{}\".format(e+1,epochs),\n",
    "              \"Batch {}/{}\".format(batch,len(trainloader)),\n",
    "              \"Train loss {:.3f}\".format(running_loss/batch),\n",
    "              \"Time per batch: {:.3f} seconds\".format((time.time() - start)/batch)\n",
    "             )\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(f\"Epoch {e} Running loss {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        \n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        accuracy = 0\n",
    "        test_loss = 0 \n",
    "        \n",
    "        model.eval() #enter inference mode wiout dropout\n",
    "        \n",
    "        for images, labels in testloader:\n",
    "            # Move input and label tensors to the GPU or CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p,top_class = ps.topk(1,dim=1)\n",
    "                equal = (top_class == labels.view(*top_class.shape))\n",
    "                accuracy += (torch.mean(equal.type(torch.FloatTensor)))\n",
    "                \n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        model.train() # return to a training mode with dropout\n",
    "\n",
    "        print(\"Epoch {}/{}\".format(e+1,epochs),\n",
    "              \"Train loss {:.3f}\".format(running_loss/len(trainloader)),\n",
    "              \"Test  loss {:.3f}\".format(test_loss/len(testloader)),\n",
    "              \"Accuracy   {:.3f}\".format(accuracy/len(testloader)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x141a25e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 384
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses,label=\"Training loss\")\n",
    "plt.plot(test_losses,label=\"Test loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
