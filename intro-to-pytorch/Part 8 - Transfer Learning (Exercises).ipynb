{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# fix for MacOS \n",
    "#\n",
    "# from https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "#\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([\n",
    "                        transforms.RandomRotation(30),\n",
    "                        transforms.RandomResizedCrop(224),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor()\n",
    "                        ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=2, bias=True)\n",
       "  (output): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0233,  0.0027,  0.0043,  ...,  0.0288,  0.0305, -0.0330],\n",
      "        [ 0.0136,  0.0029,  0.0228,  ...,  0.0102,  0.0168, -0.0156],\n",
      "        [ 0.0314,  0.0211, -0.0223,  ...,  0.0260, -0.0090, -0.0263],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0266, -0.0054,  ...,  0.0014, -0.0274,  0.0021],\n",
      "        [-0.0167, -0.0076,  0.0115,  ...,  0.0178, -0.0059, -0.0300],\n",
      "        [-0.0204, -0.0020,  0.0112,  ..., -0.0001, -0.0002, -0.0247]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.7064e-02,  2.6264e-02, -2.8891e-02, -1.3818e-02, -7.2693e-03,\n",
      "        -2.9858e-02, -7.9013e-03, -1.1171e-02, -2.7903e-02, -1.5003e-02,\n",
      "         2.9605e-02,  6.1678e-03,  8.8269e-06, -3.2076e-02,  1.2446e-02,\n",
      "        -2.5632e-02,  3.3819e-03,  2.3183e-03, -1.1259e-02,  2.5075e-02,\n",
      "        -1.9740e-02, -1.2796e-02,  3.1755e-02, -1.8166e-02,  1.8127e-02,\n",
      "         1.7470e-02,  2.4148e-02,  1.1877e-02,  1.7943e-02,  7.6680e-03,\n",
      "         2.5023e-02,  2.6920e-02, -2.2090e-03, -2.5244e-02,  1.9749e-02,\n",
      "        -1.7984e-02,  2.4346e-03,  1.8134e-02,  1.1109e-02,  3.0044e-02,\n",
      "         9.6920e-03,  2.2403e-02, -6.0227e-03,  8.7315e-03, -2.0315e-02,\n",
      "        -2.9190e-02,  3.6411e-03, -2.0501e-02, -8.0870e-03, -2.3079e-02,\n",
      "         1.7309e-02, -1.5988e-02,  2.2739e-02, -6.9793e-03, -3.2198e-03,\n",
      "         2.4279e-02, -1.5222e-03,  1.6445e-02,  2.5272e-02,  2.5184e-02,\n",
      "         2.8768e-02, -2.1348e-02,  1.5536e-03,  3.1550e-02, -1.0237e-02,\n",
      "        -1.4137e-02,  1.9855e-02,  2.8654e-02,  2.8908e-02,  2.3967e-02,\n",
      "         1.3454e-02,  2.8247e-02,  1.0268e-02,  1.5507e-02, -2.6564e-02,\n",
      "         2.5402e-02, -3.7258e-03,  2.5009e-02, -1.0473e-02, -2.4612e-02,\n",
      "        -3.3537e-02,  1.6457e-02, -1.8129e-02,  1.3617e-02, -2.5596e-02,\n",
      "        -1.6845e-04, -2.8754e-02,  1.0591e-02, -1.8348e-02,  1.2210e-02,\n",
      "         5.7484e-04,  9.8975e-03, -2.3194e-02, -8.4279e-03, -9.1200e-03,\n",
      "        -3.1538e-02,  3.0567e-02,  1.1059e-02,  1.2453e-02,  2.3952e-02,\n",
      "         6.0473e-03,  2.6899e-02,  4.0779e-03, -3.8403e-03, -3.0469e-02,\n",
      "        -2.5291e-02, -1.6836e-02,  2.3940e-02, -1.7630e-02,  5.1313e-03,\n",
      "        -5.5273e-03, -2.3661e-03, -2.8871e-02,  8.6760e-03, -4.5130e-03,\n",
      "        -1.0631e-02, -2.3531e-02, -1.6403e-02,  8.1494e-03, -1.3646e-02,\n",
      "         1.8322e-02,  1.8671e-02, -3.1822e-02,  1.4424e-02, -2.5010e-02,\n",
      "         7.9716e-03, -2.0985e-02, -6.9938e-03,  7.0911e-03, -3.0629e-02,\n",
      "        -2.8422e-04,  3.0205e-02, -1.9828e-02, -1.6026e-02, -1.7300e-02,\n",
      "        -2.4760e-02, -2.4042e-02, -2.3730e-02,  1.2343e-02,  1.8321e-02,\n",
      "         2.1593e-02, -3.7572e-03,  1.0444e-02,  9.3488e-03, -1.8120e-02,\n",
      "        -1.5461e-02, -9.0053e-03, -9.4815e-03,  4.9494e-03, -1.4591e-02,\n",
      "         1.4561e-02, -3.3276e-02, -2.8824e-02, -1.1043e-02, -1.4198e-02,\n",
      "        -2.1525e-02, -1.4574e-02,  5.2833e-03,  1.5422e-02, -1.0494e-02,\n",
      "         2.3128e-02,  1.7761e-02,  2.6678e-02,  1.5599e-02, -1.5628e-03,\n",
      "        -1.3395e-02, -1.1820e-02, -2.2811e-02, -1.1310e-02,  2.3806e-03,\n",
      "        -1.3356e-02, -2.1696e-02,  9.8489e-03,  2.9123e-02, -2.1587e-02,\n",
      "        -1.5666e-02,  9.0410e-03,  3.2080e-03,  2.1725e-02,  2.3143e-02,\n",
      "         2.4607e-02,  2.7471e-02,  1.3766e-02,  1.9617e-02, -2.8993e-02,\n",
      "         8.1638e-03, -2.1847e-02, -2.0131e-02, -1.1235e-02,  1.1790e-02,\n",
      "         1.9572e-03, -2.1474e-02, -4.5535e-03,  1.5788e-02,  2.9990e-02,\n",
      "         6.6650e-03,  1.2878e-02,  1.4695e-02,  2.4614e-02,  3.5266e-03,\n",
      "        -9.1092e-04,  2.2809e-02,  1.1426e-02,  1.8225e-02, -2.2514e-02,\n",
      "         4.7572e-03,  1.3087e-02, -1.8130e-02, -2.4369e-03, -2.5120e-02,\n",
      "         1.4337e-02,  6.7107e-03, -2.5847e-02,  2.3064e-03,  1.7464e-02,\n",
      "        -4.2495e-03,  9.9907e-03, -8.4391e-03, -1.5925e-02, -2.1252e-02,\n",
      "         8.4082e-03,  1.8225e-02,  3.2716e-02, -2.5185e-02,  4.3479e-03,\n",
      "         1.7505e-02,  6.9814e-03,  7.9975e-03, -2.5430e-02,  2.9935e-02,\n",
      "         1.5703e-02,  9.6905e-03, -1.2827e-02,  1.5751e-02,  3.9595e-03,\n",
      "         2.3491e-02, -1.3724e-02, -7.7615e-03, -7.5011e-03, -1.2131e-02,\n",
      "        -4.0789e-03, -2.5435e-02, -3.0008e-02, -1.3110e-02, -1.2800e-02,\n",
      "         3.1563e-02, -1.4782e-02,  6.0965e-03, -2.3296e-03,  1.2111e-02,\n",
      "        -2.0013e-02,  4.0249e-03,  1.3674e-02,  1.4180e-02, -6.6376e-03,\n",
      "        -1.4722e-02,  2.2865e-02, -2.2760e-02,  1.5552e-02,  3.1708e-02,\n",
      "        -4.5817e-03,  1.0671e-02, -2.5059e-02, -9.0446e-03,  2.4731e-02,\n",
      "        -1.0327e-02,  4.3184e-03,  3.2634e-02,  1.6337e-02,  2.3741e-02,\n",
      "         2.6053e-02, -1.6493e-03, -1.9447e-02,  1.6766e-03, -2.7589e-02,\n",
      "        -1.0587e-02,  2.9540e-02, -1.3547e-02,  6.8730e-04,  4.3237e-03,\n",
      "         1.0729e-02, -1.0183e-02,  2.2190e-03,  3.2229e-02,  8.6027e-04,\n",
      "        -6.9836e-03, -3.6189e-03, -2.0829e-02,  3.7895e-03, -7.3209e-03,\n",
      "        -5.1957e-04, -8.2511e-03,  2.7946e-02,  3.7422e-03, -2.4209e-02,\n",
      "        -1.3858e-02,  2.2519e-02, -1.6268e-02,  6.5660e-03,  2.0096e-02,\n",
      "         2.6054e-03,  2.7623e-03, -1.3740e-02, -1.2535e-02,  6.4983e-03,\n",
      "         8.2275e-03, -5.6890e-05, -1.7231e-02,  3.4020e-02,  9.5364e-03,\n",
      "        -2.4521e-02, -4.6730e-03, -3.1250e-03,  1.2054e-02, -4.9314e-03,\n",
      "         2.6118e-02,  8.5440e-03,  1.8337e-02, -1.7305e-02, -1.1244e-02,\n",
      "        -1.3781e-02,  1.1065e-02,  3.1450e-02,  2.6724e-03, -2.4790e-02,\n",
      "        -1.7451e-02, -7.3701e-03, -6.6006e-03, -7.0593e-03,  2.5570e-04,\n",
      "         3.2460e-03, -2.2666e-02, -1.9139e-02,  2.7954e-02, -2.9430e-02,\n",
      "         2.7038e-02,  2.2776e-02,  2.8259e-02, -9.5383e-03, -3.7205e-03,\n",
      "        -1.5122e-02, -1.2482e-02,  2.1520e-02, -2.4115e-02,  1.4902e-02,\n",
      "        -2.2068e-03,  3.0411e-02,  2.3301e-02,  1.9836e-02,  9.4685e-03,\n",
      "        -1.5824e-02,  1.4595e-02,  2.2102e-02,  1.4053e-03, -2.0728e-04,\n",
      "        -6.9697e-03,  1.4497e-02, -2.3172e-02, -1.5016e-02, -2.7175e-03,\n",
      "         1.1933e-02, -1.1976e-03, -1.1075e-02, -2.8275e-02,  2.3948e-02,\n",
      "         1.0039e-02, -2.6579e-02, -2.2018e-02,  5.5661e-03,  2.7510e-02,\n",
      "        -1.0681e-02, -2.6046e-02, -2.7749e-02, -2.3655e-02,  1.8027e-02,\n",
      "         2.0440e-02, -2.2530e-02, -1.9841e-02,  3.0714e-04, -3.8068e-03,\n",
      "        -1.4371e-02, -3.6706e-03,  4.0617e-03, -1.6159e-02,  2.0668e-03,\n",
      "         2.2700e-02, -2.8173e-02,  1.2159e-02, -2.7133e-02, -1.1249e-02,\n",
      "        -9.4135e-03, -2.9876e-03, -7.3449e-03,  1.5626e-02, -1.1813e-02,\n",
      "         2.2484e-02,  1.1570e-02, -1.1921e-02, -8.8478e-03, -5.2725e-03,\n",
      "        -3.6165e-03,  2.1592e-02,  1.4503e-02, -1.9898e-02, -1.8350e-03,\n",
      "        -1.3592e-02,  1.1069e-02,  1.0448e-02,  2.5322e-02,  1.8101e-02,\n",
      "         9.9669e-03, -1.6531e-02,  1.6279e-03,  1.7446e-02, -5.0822e-03,\n",
      "         1.6282e-02, -3.1028e-02,  1.3924e-02, -1.9918e-02,  6.8139e-03,\n",
      "        -1.5213e-02,  2.2886e-03,  7.8285e-03,  1.1806e-02,  1.9605e-02,\n",
      "        -2.7956e-02, -1.6361e-02, -2.1700e-02, -3.6626e-03, -3.5271e-03,\n",
      "        -2.4727e-02, -3.1723e-02,  7.8503e-03,  1.2511e-02, -1.7079e-02,\n",
      "         1.9495e-02,  1.7438e-02, -2.9153e-02, -9.1697e-03, -2.3116e-02,\n",
      "         6.8698e-03, -7.2119e-03, -2.5783e-02, -2.9543e-02, -4.9893e-03,\n",
      "         7.0073e-03, -1.3828e-02, -3.5524e-03,  9.1602e-03,  8.5244e-03,\n",
      "        -1.5026e-02,  7.0958e-05,  3.0295e-02, -2.3686e-03, -8.0918e-03,\n",
      "        -2.2900e-02, -5.3966e-03, -2.1626e-02, -1.4821e-02,  1.1796e-02,\n",
      "        -1.8585e-02, -1.5890e-02,  1.4114e-03,  5.0686e-03,  4.4562e-05,\n",
      "         1.2101e-02,  4.0320e-03, -2.0931e-02,  1.8870e-02, -3.1003e-02,\n",
      "        -5.7012e-03, -2.7041e-02, -5.5567e-03,  1.3305e-02,  1.4519e-02,\n",
      "         1.7644e-02,  2.4968e-02,  2.9215e-02,  5.7596e-03, -1.1404e-02,\n",
      "        -2.5307e-02, -2.9384e-02, -1.2989e-02, -6.8818e-04, -1.9067e-02,\n",
      "        -6.2666e-03, -1.7372e-02,  1.7252e-02, -1.5702e-02, -2.7474e-03,\n",
      "        -2.1569e-02,  6.9312e-03, -8.0048e-04, -2.9142e-02,  6.9466e-03,\n",
      "        -2.6915e-03, -1.0524e-02, -9.6864e-03,  1.8238e-02,  1.6655e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-7.7378e-03,  2.2378e-02,  2.0194e-02,  3.5212e-03, -2.9843e-02,\n",
      "          3.8690e-02,  6.2625e-03, -2.5935e-02, -3.3436e-02,  1.1237e-02,\n",
      "          7.1968e-03, -3.9428e-02,  3.9529e-02, -3.4137e-03,  3.2267e-02,\n",
      "         -3.8545e-02,  1.2701e-02, -2.2713e-02,  3.2944e-02,  2.6572e-02,\n",
      "         -1.8891e-02,  1.0648e-02,  4.8210e-03, -4.5502e-02, -3.9687e-03,\n",
      "         -3.7142e-02,  6.6513e-03, -3.0232e-02, -4.2734e-02,  8.6702e-03,\n",
      "         -4.7077e-03,  3.5417e-02,  3.7298e-02, -1.6574e-02,  4.1936e-02,\n",
      "          4.7167e-03, -1.8889e-02,  3.1291e-03, -2.3696e-03, -1.5562e-02,\n",
      "         -3.5301e-02, -1.9740e-02, -3.2057e-02, -2.8991e-02, -3.5069e-02,\n",
      "         -3.7382e-02, -3.0229e-02,  1.5608e-02, -3.2265e-02,  3.0017e-02,\n",
      "          2.9095e-02, -2.2408e-02,  2.0496e-02, -2.9550e-03,  1.7506e-02,\n",
      "          8.1387e-03,  7.4721e-03,  8.1353e-03, -4.0763e-02, -9.2773e-03,\n",
      "         -1.7816e-02, -3.4073e-02, -2.3800e-02, -3.8267e-03,  3.1033e-02,\n",
      "          2.4542e-02, -1.2758e-02, -2.4203e-02, -4.2932e-03,  1.1323e-02,\n",
      "         -2.3044e-02, -7.6449e-03, -4.8558e-03, -4.4252e-02,  6.6909e-03,\n",
      "          3.0486e-02,  2.8596e-02,  5.9885e-03, -3.8060e-02, -1.6491e-02,\n",
      "         -3.7979e-02,  3.1262e-02, -1.0757e-02,  2.0839e-03, -3.6999e-02,\n",
      "         -6.7193e-03,  3.5375e-02,  4.1825e-02, -3.2721e-02,  2.7076e-04,\n",
      "          2.3173e-02, -3.3831e-02,  2.5289e-02, -3.2655e-02, -3.1711e-02,\n",
      "         -4.4656e-02, -7.3725e-03,  4.4481e-02, -9.5903e-04, -3.5952e-02,\n",
      "          2.2678e-02, -2.3790e-02, -2.2832e-02,  2.6354e-02,  2.0342e-02,\n",
      "         -2.4904e-02, -6.1655e-03,  1.3596e-02, -1.6008e-02, -2.3384e-02,\n",
      "         -1.3991e-02,  4.7532e-02,  4.2124e-02, -3.2675e-02,  1.2008e-02,\n",
      "         -2.5907e-02, -4.6517e-02,  4.4583e-02, -6.3565e-03,  1.1324e-02,\n",
      "         -4.4218e-02, -4.0420e-02, -2.0029e-02, -6.4112e-03, -2.5311e-02,\n",
      "         -4.2479e-02,  3.1973e-02, -1.3036e-02,  1.3404e-02,  3.4184e-02,\n",
      "         -1.7694e-02,  2.6747e-02,  1.6976e-02,  2.8884e-02,  3.5233e-02,\n",
      "         -9.7459e-03, -5.1732e-03,  2.8603e-02,  3.7627e-02,  1.4776e-02,\n",
      "         -6.1865e-03,  3.4085e-03,  3.4817e-02, -2.0808e-02, -4.9615e-03,\n",
      "          3.2162e-02, -4.2360e-02,  3.8228e-02, -2.7895e-02,  3.0526e-02,\n",
      "          3.5095e-02, -3.3298e-02, -4.6218e-02,  8.5232e-03,  2.5494e-02,\n",
      "         -1.7719e-02,  3.0480e-02,  4.1285e-02,  1.5885e-02, -2.2724e-02,\n",
      "          2.4917e-03, -2.6760e-02, -1.1114e-03,  3.6568e-02, -6.4607e-03,\n",
      "         -4.1373e-02,  2.8040e-02,  1.1288e-02,  3.6918e-02, -3.3470e-04,\n",
      "         -9.2328e-03,  2.3755e-02,  3.6692e-02, -3.6731e-02,  8.0943e-03,\n",
      "         -6.7385e-03, -4.1640e-03, -2.2548e-02,  3.2775e-02, -2.7997e-02,\n",
      "         -1.4258e-02, -2.3779e-02,  2.2064e-02,  1.5894e-02,  3.6393e-02,\n",
      "          1.6321e-02, -1.9329e-02, -3.2452e-03,  3.9568e-02, -2.9113e-02,\n",
      "         -2.0158e-02, -2.8758e-02,  1.8667e-02, -1.7710e-02,  1.6839e-02,\n",
      "          2.9460e-02, -6.4444e-03, -8.4821e-03, -3.7272e-02,  1.3503e-02,\n",
      "          8.5527e-03,  4.5463e-02,  8.6672e-03,  2.1654e-02,  1.3994e-03,\n",
      "          3.0694e-02, -3.4857e-02, -3.0446e-02,  4.1894e-02,  3.6869e-02,\n",
      "          1.6396e-02, -3.6059e-02, -3.3690e-03, -1.8262e-02,  2.1335e-02,\n",
      "         -2.9340e-02, -5.7390e-03, -2.2616e-02, -9.9553e-03,  2.2365e-02,\n",
      "          4.4363e-02,  3.3371e-02,  3.7032e-02, -7.0803e-03,  3.7684e-02,\n",
      "          1.3801e-02, -3.8678e-02, -1.4764e-02,  1.8471e-02, -2.8125e-02,\n",
      "          1.3923e-02, -3.7386e-02, -6.0059e-03,  3.3712e-02,  3.5950e-02,\n",
      "          5.9480e-03,  3.9068e-02, -2.9399e-02,  1.8187e-02,  1.5122e-03,\n",
      "          1.1228e-02,  2.9587e-03,  1.8962e-02, -2.1239e-02,  3.1614e-02,\n",
      "          2.8775e-02,  5.2343e-03,  3.7797e-02, -4.5066e-02, -5.1170e-03,\n",
      "         -1.5055e-02,  2.2252e-03, -1.1167e-02,  1.9706e-03,  1.7071e-02,\n",
      "         -3.9088e-02, -3.5408e-02,  6.4687e-03, -3.5511e-02, -3.1284e-02,\n",
      "          4.0282e-02,  1.9549e-02, -2.7956e-03, -2.6394e-02,  5.9207e-03,\n",
      "          4.0812e-02,  2.6977e-02,  1.9118e-02,  9.1643e-04, -1.0453e-02,\n",
      "          3.7970e-02, -6.6099e-03,  3.1610e-02,  2.9163e-02, -2.6624e-02,\n",
      "          2.3981e-02, -1.2406e-02,  4.1121e-02, -3.9033e-02, -3.8357e-03,\n",
      "          3.9227e-03, -8.0484e-03, -4.1177e-02,  8.3841e-04, -2.1948e-02,\n",
      "          8.6398e-03,  1.9717e-02, -4.2115e-02, -4.3074e-02,  4.3183e-02,\n",
      "         -9.7325e-03, -7.3752e-03,  2.4145e-02,  2.3986e-03, -1.4817e-02,\n",
      "          2.5445e-02,  3.3736e-02,  3.2024e-02, -9.7394e-03,  2.7069e-02,\n",
      "          4.2218e-02, -3.1879e-02,  1.5780e-02,  2.5803e-02,  1.8588e-02,\n",
      "         -1.5303e-02, -2.1681e-03, -8.4970e-03,  1.5718e-02, -1.0503e-02,\n",
      "          8.6324e-03,  1.5043e-02,  3.5412e-02,  4.4888e-02,  3.2989e-02,\n",
      "         -5.5482e-03,  1.7539e-02,  1.9057e-02,  6.5794e-03,  4.2674e-02,\n",
      "         -1.2473e-02,  2.8534e-02,  4.2417e-02, -3.2598e-02,  2.5494e-02,\n",
      "          4.2348e-02,  3.1899e-02,  2.0506e-02,  1.5451e-02, -4.2683e-02,\n",
      "         -2.4773e-03, -9.3603e-03,  1.4706e-02, -9.9911e-03,  3.5446e-02,\n",
      "         -1.7399e-02, -2.9282e-02,  9.3138e-03, -5.8958e-03,  8.5131e-03,\n",
      "          1.1121e-02, -2.1347e-02, -7.9477e-03,  2.7467e-02,  3.1188e-02,\n",
      "          4.2216e-02,  2.8591e-02,  2.9077e-02, -8.4616e-03, -2.5448e-03,\n",
      "         -5.1474e-03, -2.0201e-02,  3.7437e-02,  8.9105e-03,  2.9161e-02,\n",
      "          2.0018e-02, -1.6552e-02,  4.4685e-02,  5.1771e-03, -2.2369e-02,\n",
      "          4.5231e-02,  1.0549e-02,  1.0316e-02,  3.1514e-02, -2.5116e-02,\n",
      "         -1.7930e-02,  3.6523e-02, -1.9657e-02,  3.6479e-02,  1.7530e-02,\n",
      "          1.0521e-02, -2.1282e-02,  3.1072e-02,  8.5918e-03,  2.5498e-02,\n",
      "          9.0801e-03,  8.4478e-04,  2.5213e-02, -5.9328e-03, -3.8437e-02,\n",
      "          2.2328e-02,  3.2784e-03, -1.5382e-02,  5.9596e-04, -3.8775e-02,\n",
      "          1.8800e-02, -3.4380e-02, -4.1348e-02,  9.9924e-03, -5.3178e-03,\n",
      "         -8.6389e-03,  3.3068e-02,  4.1489e-02,  1.0255e-02,  1.5410e-02,\n",
      "          3.9582e-02,  9.7358e-03, -4.0557e-02,  4.9180e-03, -1.8291e-02,\n",
      "         -2.6693e-02, -5.6875e-03,  3.4992e-02, -1.3196e-02, -1.0802e-02,\n",
      "         -4.0711e-02, -3.5687e-03,  3.6275e-02, -3.7079e-02,  3.3189e-02,\n",
      "          6.9988e-03, -8.5747e-03,  4.0546e-02, -1.0292e-02, -2.9212e-03,\n",
      "          4.1851e-02, -3.6259e-02,  2.1563e-02, -2.3372e-02, -3.8720e-02,\n",
      "          2.9194e-03,  1.6256e-03,  3.4332e-03, -2.6866e-02, -2.9982e-02,\n",
      "          1.1554e-02, -1.3467e-02,  2.5269e-02, -3.6530e-02, -2.1115e-02,\n",
      "          2.6452e-02, -1.7366e-02, -4.3499e-02,  2.2403e-03,  3.1843e-03,\n",
      "         -4.0448e-02, -2.6313e-03,  6.5751e-03,  8.4767e-03, -3.2576e-05,\n",
      "         -1.6335e-02, -3.2828e-02, -9.6476e-03,  4.2128e-02,  6.2425e-04,\n",
      "         -4.0324e-02, -2.7247e-02, -2.0925e-02,  4.0921e-02,  1.3731e-02,\n",
      "          2.9565e-02,  1.5706e-02, -1.6031e-02, -2.6169e-02,  1.5755e-02,\n",
      "          2.2409e-02,  3.1828e-02,  2.1078e-02,  7.9303e-03, -3.7228e-02,\n",
      "          3.4022e-02,  2.0311e-02,  5.3399e-03,  1.4930e-02, -1.6751e-02,\n",
      "          3.8563e-02,  4.2678e-02,  2.9232e-03,  3.7950e-02, -1.7650e-02,\n",
      "          1.5808e-02, -2.7109e-02,  3.9478e-02,  3.0854e-02, -3.1667e-02,\n",
      "         -2.5135e-02, -3.5627e-02,  2.6681e-02, -3.9233e-02,  5.9431e-03,\n",
      "          1.8915e-02,  2.4164e-02, -1.2553e-02,  1.9731e-02, -4.0757e-03,\n",
      "         -3.3959e-04, -2.2035e-02, -2.4279e-02, -2.6968e-02,  9.7525e-03,\n",
      "         -1.6033e-02, -1.8905e-02,  2.9085e-02, -1.8523e-02, -3.4993e-02,\n",
      "         -3.1733e-03, -1.5018e-02, -2.0885e-03,  4.0059e-03, -2.8592e-02],\n",
      "        [-3.3397e-02,  1.8200e-02,  3.0333e-02,  3.7561e-02,  3.8577e-02,\n",
      "          4.0982e-02,  2.6344e-02, -4.0005e-02,  2.0030e-02, -6.9677e-03,\n",
      "         -3.5973e-02, -6.3133e-03, -1.9867e-02,  3.5545e-02, -1.1060e-03,\n",
      "          3.0943e-02, -3.3231e-02,  4.3982e-02,  4.2679e-02, -1.7422e-02,\n",
      "          1.5980e-02,  3.4773e-02,  2.0695e-02, -1.2788e-02, -3.8812e-02,\n",
      "          4.6497e-02, -1.7936e-02, -2.7935e-02,  2.2569e-02,  1.3913e-03,\n",
      "         -3.0236e-02, -4.3911e-02,  3.5281e-02,  7.5256e-03, -4.3208e-02,\n",
      "          1.4374e-02,  5.9028e-03,  1.2782e-02, -1.2657e-02, -6.6133e-03,\n",
      "          2.6929e-02,  1.3304e-02,  2.7874e-02, -2.9136e-02, -4.2229e-03,\n",
      "          3.0944e-02, -1.1108e-02, -3.5902e-02, -2.3372e-02,  2.3277e-02,\n",
      "         -1.4420e-02,  3.6234e-02,  2.9113e-02,  3.1125e-02,  2.2086e-02,\n",
      "          3.9969e-02,  4.3591e-03, -3.6198e-02,  3.1431e-02,  1.5919e-02,\n",
      "          8.2720e-03, -2.0166e-03,  2.8011e-02,  5.7955e-03,  4.6347e-02,\n",
      "          2.6781e-02, -2.9229e-02, -1.4691e-02,  3.2459e-02, -6.6878e-03,\n",
      "          3.7964e-02,  2.2445e-02, -4.6800e-02,  5.3969e-03, -7.9899e-03,\n",
      "          1.5331e-02,  4.3731e-02, -3.2161e-02,  3.4406e-02, -3.4800e-02,\n",
      "         -1.2668e-04,  2.7124e-02,  1.6603e-02,  2.7354e-02, -8.2735e-03,\n",
      "         -2.6720e-02, -3.4120e-02,  3.4071e-02, -9.1205e-03,  2.0690e-02,\n",
      "          9.6644e-04, -4.6735e-02,  3.8541e-02, -4.1089e-02,  2.9241e-02,\n",
      "         -2.0198e-02, -1.8306e-02, -3.9254e-02, -2.3255e-02,  4.5409e-02,\n",
      "          3.3614e-02,  9.1206e-03,  6.5091e-03, -1.8227e-02, -3.3670e-02,\n",
      "          3.3155e-02, -3.3117e-02,  3.8416e-02, -4.9643e-03,  3.0644e-02,\n",
      "          4.3310e-02,  1.4993e-02,  4.6771e-03,  4.5513e-03, -2.5115e-03,\n",
      "         -9.9364e-03,  1.3079e-02, -2.9017e-02,  1.7928e-02,  5.7493e-04,\n",
      "          4.4872e-02, -1.8218e-02, -3.9464e-02,  7.8974e-03, -3.8328e-03,\n",
      "          3.1293e-02, -3.1581e-02, -6.4712e-03,  3.7942e-02, -2.0980e-02,\n",
      "         -4.3255e-02, -3.1974e-02,  2.7742e-02,  1.6167e-02, -3.4896e-02,\n",
      "          3.4160e-02,  1.0386e-02, -2.3298e-02,  1.6286e-02,  3.1072e-02,\n",
      "          3.2433e-02, -1.8887e-03,  1.9659e-02,  4.5429e-03,  3.5690e-02,\n",
      "         -4.0316e-02, -2.6913e-02, -2.1686e-02, -2.8866e-02, -3.5310e-02,\n",
      "          4.1698e-02,  1.7785e-02, -3.3938e-02, -1.1727e-02, -2.7591e-03,\n",
      "         -3.3852e-02, -3.1661e-02, -6.3680e-03,  3.6962e-02, -8.9687e-03,\n",
      "         -2.9198e-02, -2.3825e-02,  6.4986e-03, -2.1821e-02, -3.9543e-02,\n",
      "         -8.5506e-03,  2.1191e-02, -2.9219e-02,  1.4356e-02,  1.1710e-02,\n",
      "         -5.5557e-03, -3.8768e-02,  3.8869e-02,  3.0347e-02,  2.5615e-02,\n",
      "          2.2111e-02,  5.5193e-03,  3.3469e-02, -1.0331e-02,  1.5326e-02,\n",
      "          1.5785e-02,  5.4014e-03, -3.5899e-02, -2.4490e-02,  2.4161e-02,\n",
      "         -1.9033e-02,  4.6297e-02,  2.5956e-02, -3.4258e-03,  1.6427e-02,\n",
      "          2.2105e-02, -3.3199e-02, -4.4003e-04,  1.9689e-03,  1.1137e-02,\n",
      "          8.7725e-03, -2.0864e-02,  3.4359e-02, -3.5513e-02,  3.7352e-02,\n",
      "         -2.2355e-02, -1.8060e-03,  9.2373e-03,  3.9369e-02,  2.9623e-02,\n",
      "          2.1410e-03,  1.2813e-03, -2.7435e-02, -2.1205e-03,  8.0127e-03,\n",
      "          8.9019e-03,  2.7827e-02,  2.2752e-02,  3.9255e-02, -7.3741e-04,\n",
      "          2.8975e-02,  2.4843e-02,  1.3594e-02, -1.9635e-02, -3.6212e-03,\n",
      "          1.0180e-02, -1.2293e-02, -1.8457e-02,  6.7286e-03,  1.6266e-03,\n",
      "          1.5443e-02, -2.6651e-02,  4.1072e-02, -1.6586e-02,  2.0125e-02,\n",
      "          4.0165e-02, -2.0362e-02,  2.8442e-02, -6.8973e-04,  1.4859e-02,\n",
      "         -2.9742e-02, -3.3389e-02, -2.0874e-02,  6.5724e-03,  3.9535e-02,\n",
      "          1.9043e-02, -1.8446e-02, -1.0034e-02, -4.1738e-02, -4.0594e-02,\n",
      "         -4.2836e-02,  1.2594e-02, -3.4918e-02,  1.4800e-02,  3.6588e-02,\n",
      "          1.3890e-02, -3.0657e-04,  1.2213e-02, -3.8529e-02,  5.3333e-03,\n",
      "         -7.8725e-03, -1.7547e-02,  9.9686e-03,  3.9368e-02, -3.9892e-02,\n",
      "          1.8089e-03, -3.4470e-02,  4.0004e-02,  1.5890e-02,  3.8108e-02,\n",
      "          1.9967e-02, -1.3918e-03, -1.1712e-03, -4.5579e-03,  7.4564e-03,\n",
      "          4.9669e-04,  3.7999e-02, -1.9011e-02,  1.6213e-03,  3.3585e-02,\n",
      "         -4.2673e-03,  3.4646e-02, -1.2626e-03, -1.2246e-02, -1.4976e-03,\n",
      "          2.0513e-02, -4.4347e-02, -1.7474e-02,  2.3299e-02, -2.1875e-02,\n",
      "         -2.4931e-03, -3.5477e-02,  8.8153e-04, -1.6685e-03, -4.2656e-02,\n",
      "         -2.1996e-02, -2.8381e-02,  3.3219e-02, -1.2940e-02, -3.0711e-02,\n",
      "         -5.2186e-03, -3.8401e-02,  1.7924e-02,  2.1712e-02, -3.1343e-03,\n",
      "         -2.3367e-02,  2.3240e-02,  2.2817e-03,  4.0433e-02,  2.5876e-02,\n",
      "         -3.2292e-02,  7.3229e-03, -2.1683e-02, -2.8478e-02,  1.2410e-02,\n",
      "          4.2404e-02, -1.2596e-02,  3.2940e-02,  2.1493e-02,  2.1766e-03,\n",
      "         -1.0715e-02,  7.9942e-03, -2.6313e-02,  3.3718e-02,  2.2450e-02,\n",
      "          2.3423e-02,  1.5185e-02, -2.4031e-02,  1.8048e-02,  3.1236e-02,\n",
      "         -2.4649e-03,  4.6312e-02,  6.9109e-03, -1.3027e-02, -1.7478e-02,\n",
      "          2.3002e-02, -9.2793e-03, -1.0713e-03, -4.7114e-02,  1.1615e-02,\n",
      "          3.3435e-02, -3.6539e-02, -3.8390e-02, -3.9825e-02, -3.0825e-02,\n",
      "          2.1248e-02,  3.7781e-02, -4.9301e-02,  3.8997e-02, -8.8094e-04,\n",
      "          3.9519e-02, -2.2315e-02,  3.0600e-02, -4.4360e-02,  3.8289e-02,\n",
      "          1.8404e-02, -2.3635e-02,  2.8443e-02,  2.4892e-02, -2.2882e-02,\n",
      "          3.6734e-02,  2.3709e-02,  9.5327e-03, -4.1523e-02,  2.7080e-02,\n",
      "         -3.0536e-02, -4.0532e-02,  9.0434e-03,  3.1119e-02,  4.1471e-02,\n",
      "         -1.6660e-02,  1.9072e-02,  4.7454e-02,  4.1864e-02,  1.3161e-03,\n",
      "          3.6969e-02, -1.8381e-02, -2.0765e-02,  1.3648e-02, -2.9520e-04,\n",
      "         -4.1017e-03, -2.3467e-02,  2.3910e-02,  1.4241e-02, -4.4817e-02,\n",
      "         -1.3236e-02, -1.9555e-02, -1.4971e-02,  1.4092e-02, -1.1729e-02,\n",
      "         -7.2682e-03, -2.2347e-02, -4.0787e-02,  1.3499e-02, -1.3786e-02,\n",
      "         -2.3969e-02, -1.4646e-02, -2.1768e-02,  5.1913e-03, -2.7192e-02,\n",
      "          2.5486e-02,  1.9303e-02,  2.5487e-02, -1.6384e-02,  4.3635e-02,\n",
      "          7.7801e-03,  3.5841e-02,  1.6054e-02, -9.5752e-03, -6.2931e-03,\n",
      "          1.8452e-02,  9.5598e-03,  1.1717e-02,  3.4680e-03,  3.3492e-02,\n",
      "          2.1981e-02,  3.5825e-02,  1.9190e-02, -1.3187e-02,  1.6634e-02,\n",
      "          1.6111e-02,  4.7658e-04, -3.5317e-02, -1.3482e-03, -2.5779e-02,\n",
      "          3.1026e-02,  2.4045e-02, -1.5550e-02, -4.1139e-02,  1.5782e-02,\n",
      "         -3.7548e-03, -1.7481e-02,  4.3586e-03,  4.2620e-02, -1.4671e-02,\n",
      "          1.2746e-02,  4.0536e-02,  4.7105e-02,  3.4199e-02, -2.1910e-02,\n",
      "          3.2223e-02,  1.9101e-03, -4.5645e-03, -2.1679e-02,  2.5160e-02,\n",
      "         -1.1161e-02,  3.7891e-02, -1.6255e-02, -2.9381e-02,  1.9400e-02,\n",
      "         -2.8726e-02,  3.5374e-02,  1.9632e-02, -3.4178e-02,  2.5450e-02,\n",
      "         -3.5241e-02,  3.2495e-02, -3.9379e-02, -1.2577e-02,  3.6533e-02,\n",
      "         -1.6963e-02, -4.2702e-02, -1.3846e-02,  4.9682e-03,  3.5442e-02,\n",
      "          3.7938e-02, -3.5595e-03,  1.1641e-02, -1.0240e-02, -2.4849e-02,\n",
      "         -4.5214e-03,  4.8414e-03,  2.6556e-02,  9.6639e-03,  2.5696e-02,\n",
      "          1.2229e-02,  2.6582e-02, -4.7635e-02,  3.2956e-02, -2.4756e-02,\n",
      "         -3.3785e-02,  1.6323e-02, -3.9623e-02, -2.6419e-02, -2.1568e-02,\n",
      "         -9.0496e-03,  3.7622e-02, -1.3963e-02,  3.4017e-02,  3.1627e-02,\n",
      "         -2.8242e-02,  3.5545e-02, -2.1432e-02,  5.2252e-03, -1.8969e-02,\n",
      "         -3.5004e-02, -5.9944e-03, -2.2517e-02, -3.6595e-02, -1.0484e-02,\n",
      "         -4.1569e-02,  2.8256e-02, -1.3376e-02,  3.5696e-03, -1.6675e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0432, -0.0315], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
    "\n",
    "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cpu; Time per batch: 6.299 seconds\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu'] :   #['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Move input and label tensors to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
    "```python\n",
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Use a pretrained model to classify the cat and dog images\n",
    "\n",
    "device = 'cpu' #\"cuda\"\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        # Move input and label tensors to the GPU or CPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Epoch {e} Running loss {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        \n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        accuracy = 0\n",
    "        test_loss = 0 \n",
    "        \n",
    "        model.eval() #enter inference mode wiout dropout\n",
    "        \n",
    "        for images, labels in testloader:\n",
    "            # Move input and label tensors to the GPU or CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p,top_class = ps.topk(1,dim=1)\n",
    "                equal = (top_class == labels.view(*top_class.shape))\n",
    "                accuracy += (torch.mean(equal.type(torch.FloatTensor)))\n",
    "                \n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        model.train() # return to a training mode with dropout\n",
    "\n",
    "        print(\"Epoch {}/{}\".format(e+1,epochs),\n",
    "              \"Train loss {:.3f}\".format(running_loss/len(trainloader)),\n",
    "              \"Test  loss {:.3f}\".format(test_loss/len(testloader)),\n",
    "              \"Accuracy   {:.3f}\".format(accuracy/len(testloader)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses,label=\"Training loss\")\n",
    "plt.plot(test_losses,label=\"Test loss\")\n",
    "plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
